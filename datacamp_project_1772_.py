# -*- coding: utf-8 -*-
"""DataCamp Project 1772 .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rtk595vgkQmK2IbfOCept96kQNKtcgmR
"""

#Project: https://projects.datacamp.com/projects/1772

# All required libraries are imported here for you.
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold

# Load the dataset
crops = pd.read_csv("soil_measures.csv")

# Set random seed
seed = 1

# Data Exploration
def EDA (df):
    print('Preview: \n', df.head())
    print('Shape of DataFrame: \n', df.shape)
    print('Type of Columns: \n', df.dtypes)
    print('Null in Each Column: \n', df.isnull().sum())
    print('Unique Type of Target: \n', df['crop'].unique())


# Best feature and score
def best_feature(features):

    # Empty Dictionary
    best_predictive = {}

    # Instantiate Logistic Regression
    lr = LogisticRegression(max_iter = 200, random_state = seed)

    # Hyperparameter Tuning - solver
    params = {'C':[0.1, 1, 10],
            'solver':['lbfgs', 'saga'],
            'multi_class':['multinomial', 'ovr']}

    kf = KFold(n_splits = 5, shuffle = True, random_state = seed)

    lr_gs = GridSearchCV(estimator = lr,
                        param_grid = params,
                        cv = kf,
                        scoring = 'accuracy',
                        n_jobs = -1)

    for feature in features:
        # Train Test Split
        X = crops[feature].values.reshape(-1, 1)  # Reshape to 2D array
        y = crops['crop']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3 , random_state = seed)


        # Fit Model
        lr_gs.fit(X_train, y_train)

        # Retrieve the best parameters
        best_params = lr_gs.best_params_

        # Retrieve the best score
        best_score = lr_gs.best_score_

        #best_predictive
        best_predictive[feature] = best_score

    best_feature = max(best_predictive, key=best_predictive.get)
    best_accuracy = best_predictive[best_feature]
    best_predictive_feature = {best_feature: best_accuracy}

    return best_predictive_feature

features = ['N', 'P', 'K', 'ph']
best_feature(features)